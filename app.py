import numpy as np
import pandas as pd
from flask import Flask, jsonify, request
from flask_cors import CORS
from statsmodels.tsa.arima.model import ARIMA
import torch
import torch.nn as nn
from sklearn.preprocessing import MinMaxScaler
import warnings
import os
import random

# å¿½ç•¥è­¦å‘Šï¼Œä¿æŒæ§åˆ¶å°æ¸…æ´
warnings.filterwarnings("ignore")

# 1. åˆå§‹åŒ– Flask åº”ç”¨
app = Flask(__name__)
# 2. å¯ç”¨ CORSï¼Œå…è®¸å‰ç«¯ç½‘é¡µè®¿é—®
CORS(app)

# --- å®šä¹‰ LSTM æ¨¡å‹ ---
class LSTMModel(nn.Module):
    def __init__(self, input_size=2, hidden_size=50, output_size=2):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])
        return out

# --- æ—…æ¸¸æ¨èæ•°æ®æ¨¡æ‹Ÿ ---
def get_travel_recommendations(city_name):
    # ç®€å•çš„æ¨¡æ‹Ÿæ•°æ®åº“ï¼Œå®é™…å¯è¿æ¥ Google Places API æˆ– Yelp
    city_db = {
        "Beijing": {
            "food": [
                {"name": "åŒ—äº¬çƒ¤é¸­", "desc": "é…¥è„†å¤–çš®ï¼Œä¼ ç»Ÿæœæœ¨æŒ‚ç‚‰æŠ€è‰ºã€‚", "icon": "ğŸ¦†"},
                {"name": "ç‚¸é…±é¢", "desc": "è€åŒ—äº¬åœ°é“é¢é£Ÿï¼Œé…±é¦™æµ“éƒã€‚", "icon": "ğŸœ"}
            ],
            "spots": [
                {"name": "æ•…å®«åšç‰©é™¢", "desc": "ä¸–ç•Œæœ€å¤§å®«æ®¿å»ºç­‘ç¾¤ã€‚", "tag": "å†å²"},
                {"name": "798è‰ºæœ¯åŒº", "desc": "ç°ä»£è‰ºæœ¯ä¸å·¥ä¸šé£çš„å®Œç¾ç»“åˆã€‚", "tag": "è‰ºæœ¯"}
            ]
        },
        "Shanghai": {
            "food": [
                {"name": "å°ç¬¼åŒ…", "desc": "çš®è–„æ±å¤šï¼Œå—ç¿”ç‰¹è‰²ã€‚", "icon": "ğŸ¥Ÿ"},
                {"name": "ç”Ÿç…é¦’å¤´", "desc": "åº•è„†è‚‰é²œï¼Œæ’’ä¸Šè‘±èŠ±èŠéº»ã€‚", "icon": "ğŸ¥ "}
            ],
            "spots": [
                {"name": "å¤–æ»©", "desc": "ä¸‡å›½å»ºç­‘åšè§ˆç¾¤ï¼Œå¤œæ™¯è¿·äººã€‚", "tag": "åœ°æ ‡"},
                {"name": "è±«å›­", "desc": "æ±Ÿå—å¤å…¸å›­æ—ï¼Œç²¾è‡´å…¸é›…ã€‚", "tag": "å›­æ—"}
            ]
        },
        "Tokyo": {
            "food": [
                {"name": "å¯¿å¸ (Sushi)", "desc": "ç­‘åœ°å¸‚åœºæ–°é²œç›´ä¾›ã€‚", "icon": "ğŸ£"},
                {"name": "è±šéª¨æ‹‰é¢", "desc": "æµ“éƒéª¨æ±¤ï¼Œå¼¹ç‰™é¢æ¡ã€‚", "icon": "ğŸœ"}
            ],
            "spots": [
                {"name": "æµ…è‰å¯º", "desc": "ä¸œäº¬æœ€å¤è€çš„å¯ºåº™ã€‚", "tag": "æ–‡åŒ–"},
                {"name": "æ¶©è°·è·¯å£", "desc": "ä¸–ç•Œæœ€ç¹å¿™çš„åå­—è·¯å£ã€‚", "tag": "éƒ½å¸‚"}
            ]
        },
        "Paris": {
            "food": [
                {"name": "æ³•å¼ç‰›è§’åŒ…", "desc": "å±‚å±‚é…¥è„†ï¼Œé»„æ²¹é¦™æ°”ã€‚", "icon": "ğŸ¥"},
                {"name": "é©¬å¡é¾™", "desc": "å°‘å¥³çš„é…¥èƒ¸ï¼Œç”œç‚¹ä¸­çš„è´µæ—ã€‚", "icon": "ğŸª"}
            ],
            "spots": [
                {"name": "åŸƒè²å°”é“å¡”", "desc": "å·´é»é“å¨˜å­ï¼Œæµªæ¼«è±¡å¾ã€‚", "tag": "åœ°æ ‡"},
                {"name": "å¢æµ®å®«", "desc": "è’™å¨œä¸½èçš„å¾®ç¬‘æ‰€åœ¨åœ°ã€‚", "tag": "è‰ºæœ¯"}
            ]
        }
    }

    # æ¨¡ç³ŠåŒ¹é…æˆ–è¿”å›é»˜è®¤å€¼
    key = None
    for k in city_db:
        if k.lower() in city_name.lower():
            key = k
            break
    
    if key:
        return city_db[key]
    else:
        # é€šç”¨å…œåº•æ•°æ®
        return {
            "food": [
                {"name": "å½“åœ°ç‰¹è‰²å°åƒ", "desc": "æ¢ç´¢è¡—å¤´å··å°¾çš„éšè—ç¾å‘³ã€‚", "icon": "ğŸ¢"},
                {"name": "ç²¾é€‰æ–™ç†", "desc": "ä¸»å¨æ¨èçš„æ—¶ä»¤ä½³è‚´ã€‚", "icon": "ğŸ½ï¸"}
            ],
            "spots": [
                {"name": "åŸå¸‚ä¸­å¿ƒå…¬å›­", "desc": "æ„Ÿå—å½“åœ°çš„ç”Ÿæ´»èŠ‚å¥ã€‚", "tag": "ä¼‘é—²"},
                {"name": "å†å²åšç‰©é¦†", "desc": "äº†è§£è¿™åº§åŸå¸‚çš„è¿‡å»ã€‚", "tag": "æ–‡åŒ–"}
            ]
        }

# --- æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ ---
def run_ai_analysis(city_name):
    # æ¨¡æ‹Ÿç”Ÿæˆæ•°æ® (å®é™…ä¼šè¿æ¥æ•°æ®åº“)
    dates = pd.date_range('2025-11-01', periods=10)
    # ç¨å¾®æ·»åŠ ä¸€ç‚¹éšæœºæ€§
    base_temp = 20 + random.randint(-10, 10)
    temp_data = [base_temp + random.randint(-3, 3) for _ in range(10)]
    precip_data = [random.choice([0, 0, 0, 5, 15]) for _ in range(10)]
    
    df = pd.DataFrame({'temp': temp_data, 'precip': precip_data}, index=dates)

    # 1. ARIMA é¢„æµ‹
    try:
        model_arima = ARIMA(df['temp'], order=(1,1,1))
        model_fit = model_arima.fit()
        forecast_arima = model_fit.forecast(steps=5).tolist()
    except:
        forecast_arima = [base_temp] * 5

    # 2. LSTM é¢„æµ‹
    lstm_temps = []
    lstm_rain = []
    try:
        data = df.values.astype(np.float32)
        scaler = MinMaxScaler()
        data_scaled = scaler.fit_transform(data)

        X, y = [], []
        for i in range(len(data_scaled) - 3):
            X.append(data_scaled[i:i+3])
            y.append(data_scaled[i+3])
        
        if len(X) > 0:
            X_tensor = torch.from_numpy(np.array(X))
            y_tensor = torch.from_numpy(np.array(y))

            model = LSTMModel()
            criterion = nn.MSELoss()
            optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

            for _ in range(30): # å‡å°‘è®­ç»ƒè½®æ•°åŠ å¿«å“åº”
                optimizer.zero_grad()
                outputs = model(X_tensor)
                loss = criterion(outputs, y_tensor)
                loss.backward()
                optimizer.step()

            last_seq = torch.from_numpy(data_scaled[-3:]).unsqueeze(0)
            forecast_scaled = []
            for _ in range(5):
                pred = model(last_seq)
                forecast_scaled.append(pred.detach().numpy())
                pred_expanded = pred.unsqueeze(1)
                last_seq = torch.cat((last_seq[:, 1:, :], pred_expanded), dim=1)

            forecast_lstm = scaler.inverse_transform(np.concatenate(forecast_scaled, axis=0))
            lstm_temps = forecast_lstm[:, 0].tolist()
            lstm_rain = forecast_lstm[:, 1].tolist()
        else:
            raise Exception("Data too short")
            
    except Exception as e:
        print(f"LSTM Fallback: {e}")
        lstm_temps = [base_temp] * 5
        lstm_rain = [0] * 5

    # 3. ç©¿è¡£å»ºè®®
    avg_temp = sum(lstm_temps) / len(lstm_temps)
    if avg_temp > 25:
        suggestion = "AI å»ºè®®: çƒ­æµªæ¥è¢­ï¼Œå»ºè®®ç©¿ç€æ¸…å‡‰é€æ°”çš„è¡£ç‰©ã€‚"
    elif avg_temp > 15:
        suggestion = "AI å»ºè®®: æ°”å€™èˆ’é€‚ï¼ŒTæ¤æ­é…è–„å¤–å¥—å³å¯ã€‚"
    elif avg_temp > 5:
        suggestion = "AI å»ºè®®: å¤©æ°”è½¬å‡‰ï¼Œè¯·ç©¿ç€é£è¡£æˆ–å¤¹å…‹ã€‚"
    else:
        suggestion = "AI å»ºè®®: ä¸¥å¯’é¢„è­¦ï¼Œè¯·åŠ¡å¿…ç©¿ç€ç¾½ç»’æœä¿æš–ã€‚"

    # 4. è·å–æ—…æ¸¸æ¨è
    travel_data = get_travel_recommendations(city_name)

    return {
        "status": "success",
        "arima_forecast": forecast_arima,
        "lstm_forecast": {
            "temp": [round(x, 1) for x in lstm_temps],
            "rain": [round(x, 1) for x in lstm_rain]
        },
        "advice": suggestion,
        "travel": travel_data
    }

# --- è·¯ç”± ---
@app.route('/', methods=['GET'])
def home():
    return "OmniWeather åç«¯æœåŠ¡å™¨æ­£åœ¨è¿è¡Œï¼"

@app.route('/api/analyze', methods=['GET'])
def api_analyze():
    city = request.args.get('city', 'Beijing')
    print(f"æ”¶åˆ°å‰ç«¯è¯·æ±‚: åˆ†æåŸå¸‚ {city}...")
    data = run_ai_analysis(city)
    return jsonify(data)

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(debug=True, port=port)